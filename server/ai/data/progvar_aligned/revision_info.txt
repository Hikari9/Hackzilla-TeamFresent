arguments: facenet/align/align_dataset_mtcnn.py /home/rico/Git/AI-Fresent/server/ai/data/progvar_raw /home/rico/Git/AI-Fresent/server/ai/data/progvar_aligned --gpu_memory_fraction 0.68
--------------------
git hash: b'88cc2416991cde278cfb134132d15a824eeeee91'
--------------------
b'diff --git a/server/ai/data/progvar_aligned/Aemiel/aemielvin loremia 1.png b/server/ai/data/progvar_aligned/Aemiel/aemielvin loremia 1.png\ndeleted file mode 100644\nindex 16a3ff5..0000000\nBinary files a/server/ai/data/progvar_aligned/Aemiel/aemielvin loremia 1.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Aemiel/aemielvin loremia 2.png b/server/ai/data/progvar_aligned/Aemiel/aemielvin loremia 2.png\ndeleted file mode 100644\nindex 58117cb..0000000\nBinary files a/server/ai/data/progvar_aligned/Aemiel/aemielvin loremia 2.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Aemiel/aemielvin loremia 3.png b/server/ai/data/progvar_aligned/Aemiel/aemielvin loremia 3.png\ndeleted file mode 100644\nindex e2811e7..0000000\nBinary files a/server/ai/data/progvar_aligned/Aemiel/aemielvin loremia 3.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Aemiel/aemielvin loremia 4.png b/server/ai/data/progvar_aligned/Aemiel/aemielvin loremia 4.png\ndeleted file mode 100644\nindex 66a8385..0000000\nBinary files a/server/ai/data/progvar_aligned/Aemiel/aemielvin loremia 4.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Aemiel/aemielvin loremia 5.png b/server/ai/data/progvar_aligned/Aemiel/aemielvin loremia 5.png\ndeleted file mode 100644\nindex 8a8fabd..0000000\nBinary files a/server/ai/data/progvar_aligned/Aemiel/aemielvin loremia 5.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Aemiel/aemielvin loremia 6.png b/server/ai/data/progvar_aligned/Aemiel/aemielvin loremia 6.png\ndeleted file mode 100644\nindex 9034862..0000000\nBinary files a/server/ai/data/progvar_aligned/Aemiel/aemielvin loremia 6.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Aldrich/aldrich asuncion 1.png b/server/ai/data/progvar_aligned/Aldrich/aldrich asuncion 1.png\ndeleted file mode 100644\nindex 967fb50..0000000\nBinary files a/server/ai/data/progvar_aligned/Aldrich/aldrich asuncion 1.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Aldrich/aldrich asuncion 2.png b/server/ai/data/progvar_aligned/Aldrich/aldrich asuncion 2.png\ndeleted file mode 100644\nindex d182b4e..0000000\nBinary files a/server/ai/data/progvar_aligned/Aldrich/aldrich asuncion 2.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Aldrich/aldrich asuncion 3.png b/server/ai/data/progvar_aligned/Aldrich/aldrich asuncion 3.png\ndeleted file mode 100644\nindex a4ed5d1..0000000\nBinary files a/server/ai/data/progvar_aligned/Aldrich/aldrich asuncion 3.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Aldrich/aldrich asuncion 4.png b/server/ai/data/progvar_aligned/Aldrich/aldrich asuncion 4.png\ndeleted file mode 100644\nindex fb2ebe2..0000000\nBinary files a/server/ai/data/progvar_aligned/Aldrich/aldrich asuncion 4.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Aldrich/aldrich asuncion 5.png b/server/ai/data/progvar_aligned/Aldrich/aldrich asuncion 5.png\ndeleted file mode 100644\nindex f957479..0000000\nBinary files a/server/ai/data/progvar_aligned/Aldrich/aldrich asuncion 5.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Aldrich/aldrich asuncion 6.png b/server/ai/data/progvar_aligned/Aldrich/aldrich asuncion 6.png\ndeleted file mode 100644\nindex 667e332..0000000\nBinary files a/server/ai/data/progvar_aligned/Aldrich/aldrich asuncion 6.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Andre/andre tan 1.png b/server/ai/data/progvar_aligned/Andre/andre tan 1.png\ndeleted file mode 100644\nindex 21206b5..0000000\nBinary files a/server/ai/data/progvar_aligned/Andre/andre tan 1.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Andre/andre tan 2.png b/server/ai/data/progvar_aligned/Andre/andre tan 2.png\ndeleted file mode 100644\nindex 511f363..0000000\nBinary files a/server/ai/data/progvar_aligned/Andre/andre tan 2.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Andre/andre tan 3.png b/server/ai/data/progvar_aligned/Andre/andre tan 3.png\ndeleted file mode 100644\nindex 6e891f1..0000000\nBinary files a/server/ai/data/progvar_aligned/Andre/andre tan 3.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Andre/andre tan 4.png b/server/ai/data/progvar_aligned/Andre/andre tan 4.png\ndeleted file mode 100644\nindex 2f79a34..0000000\nBinary files a/server/ai/data/progvar_aligned/Andre/andre tan 4.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Andre/andre tan 5.png b/server/ai/data/progvar_aligned/Andre/andre tan 5.png\ndeleted file mode 100644\nindex 4d92272..0000000\nBinary files a/server/ai/data/progvar_aligned/Andre/andre tan 5.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Andre/andre tan 6.png b/server/ai/data/progvar_aligned/Andre/andre tan 6.png\ndeleted file mode 100644\nindex 46c6b16..0000000\nBinary files a/server/ai/data/progvar_aligned/Andre/andre tan 6.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Brian/brian guadalupe 1.png b/server/ai/data/progvar_aligned/Brian/brian guadalupe 1.png\ndeleted file mode 100644\nindex 47b0ce2..0000000\nBinary files a/server/ai/data/progvar_aligned/Brian/brian guadalupe 1.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Brian/brian guadalupe 2.png b/server/ai/data/progvar_aligned/Brian/brian guadalupe 2.png\ndeleted file mode 100644\nindex 3d4aaa5..0000000\nBinary files a/server/ai/data/progvar_aligned/Brian/brian guadalupe 2.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Brian/brian guadalupe 3.png b/server/ai/data/progvar_aligned/Brian/brian guadalupe 3.png\ndeleted file mode 100644\nindex c330109..0000000\nBinary files a/server/ai/data/progvar_aligned/Brian/brian guadalupe 3.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Brian/brian guadalupe 4.png b/server/ai/data/progvar_aligned/Brian/brian guadalupe 4.png\ndeleted file mode 100644\nindex c5e3b6f..0000000\nBinary files a/server/ai/data/progvar_aligned/Brian/brian guadalupe 4.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/DavidC/david cuajunco 1.png b/server/ai/data/progvar_aligned/DavidC/david cuajunco 1.png\ndeleted file mode 100644\nindex 6bcc425..0000000\nBinary files a/server/ai/data/progvar_aligned/DavidC/david cuajunco 1.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/DavidC/david cuajunco 2.png b/server/ai/data/progvar_aligned/DavidC/david cuajunco 2.png\ndeleted file mode 100644\nindex 0a01654..0000000\nBinary files a/server/ai/data/progvar_aligned/DavidC/david cuajunco 2.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/DavidC/david cuajunco 3.png b/server/ai/data/progvar_aligned/DavidC/david cuajunco 3.png\ndeleted file mode 100644\nindex 1f56b02..0000000\nBinary files a/server/ai/data/progvar_aligned/DavidC/david cuajunco 3.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/DavidC/david cuajunco 4.png b/server/ai/data/progvar_aligned/DavidC/david cuajunco 4.png\ndeleted file mode 100644\nindex 60d1c0d..0000000\nBinary files a/server/ai/data/progvar_aligned/DavidC/david cuajunco 4.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/DavidC/david cuajunco 5.png b/server/ai/data/progvar_aligned/DavidC/david cuajunco 5.png\ndeleted file mode 100644\nindex 06e7680..0000000\nBinary files a/server/ai/data/progvar_aligned/DavidC/david cuajunco 5.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/DavidC/david cuajunco 6.png b/server/ai/data/progvar_aligned/DavidC/david cuajunco 6.png\ndeleted file mode 100644\nindex 8cbfa9c..0000000\nBinary files a/server/ai/data/progvar_aligned/DavidC/david cuajunco 6.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/DavidD/david diy 1.png b/server/ai/data/progvar_aligned/DavidD/david diy 1.png\ndeleted file mode 100644\nindex c269b11..0000000\nBinary files a/server/ai/data/progvar_aligned/DavidD/david diy 1.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/DavidD/david diy 2.png b/server/ai/data/progvar_aligned/DavidD/david diy 2.png\ndeleted file mode 100644\nindex 0eeffdb..0000000\nBinary files a/server/ai/data/progvar_aligned/DavidD/david diy 2.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/DavidD/david diy 3.png b/server/ai/data/progvar_aligned/DavidD/david diy 3.png\ndeleted file mode 100644\nindex e964409..0000000\nBinary files a/server/ai/data/progvar_aligned/DavidD/david diy 3.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/DavidD/david diy 4.png b/server/ai/data/progvar_aligned/DavidD/david diy 4.png\ndeleted file mode 100644\nindex abd3fe5..0000000\nBinary files a/server/ai/data/progvar_aligned/DavidD/david diy 4.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/DavidD/david diy 5.png b/server/ai/data/progvar_aligned/DavidD/david diy 5.png\ndeleted file mode 100644\nindex 524983b..0000000\nBinary files a/server/ai/data/progvar_aligned/DavidD/david diy 5.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/DavidD/david diy 6.png b/server/ai/data/progvar_aligned/DavidD/david diy 6.png\ndeleted file mode 100644\nindex 8a54669..0000000\nBinary files a/server/ai/data/progvar_aligned/DavidD/david diy 6.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Deanne/deanne pascual 1.png b/server/ai/data/progvar_aligned/Deanne/deanne pascual 1.png\ndeleted file mode 100644\nindex 3eac7ae..0000000\nBinary files a/server/ai/data/progvar_aligned/Deanne/deanne pascual 1.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Deanne/deanne pascual 2.png b/server/ai/data/progvar_aligned/Deanne/deanne pascual 2.png\ndeleted file mode 100644\nindex 86d6e1d..0000000\nBinary files a/server/ai/data/progvar_aligned/Deanne/deanne pascual 2.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Deanne/deanne pascual 3.png b/server/ai/data/progvar_aligned/Deanne/deanne pascual 3.png\ndeleted file mode 100644\nindex 7bcbf0f..0000000\nBinary files a/server/ai/data/progvar_aligned/Deanne/deanne pascual 3.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Deanne/deanne pascual 4.png b/server/ai/data/progvar_aligned/Deanne/deanne pascual 4.png\ndeleted file mode 100644\nindex a63df91..0000000\nBinary files a/server/ai/data/progvar_aligned/Deanne/deanne pascual 4.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Deanne/deanne pascual 5.png b/server/ai/data/progvar_aligned/Deanne/deanne pascual 5.png\ndeleted file mode 100644\nindex aa214c7..0000000\nBinary files a/server/ai/data/progvar_aligned/Deanne/deanne pascual 5.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Deanne/deanne pascual 6.png b/server/ai/data/progvar_aligned/Deanne/deanne pascual 6.png\ndeleted file mode 100644\nindex 8859492..0000000\nBinary files a/server/ai/data/progvar_aligned/Deanne/deanne pascual 6.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Gabby/gabby sanchez 1.png b/server/ai/data/progvar_aligned/Gabby/gabby sanchez 1.png\ndeleted file mode 100644\nindex 78caf2b..0000000\nBinary files a/server/ai/data/progvar_aligned/Gabby/gabby sanchez 1.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Gabby/gabby sanchez 2.png b/server/ai/data/progvar_aligned/Gabby/gabby sanchez 2.png\ndeleted file mode 100644\nindex 841103a..0000000\nBinary files a/server/ai/data/progvar_aligned/Gabby/gabby sanchez 2.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Gabby/gabby sanchez 3.png b/server/ai/data/progvar_aligned/Gabby/gabby sanchez 3.png\ndeleted file mode 100644\nindex 4968462..0000000\nBinary files a/server/ai/data/progvar_aligned/Gabby/gabby sanchez 3.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Gabby/gabby sanchez 4.png b/server/ai/data/progvar_aligned/Gabby/gabby sanchez 4.png\ndeleted file mode 100644\nindex 2a323c9..0000000\nBinary files a/server/ai/data/progvar_aligned/Gabby/gabby sanchez 4.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Gabby/gabby sanchez 5.png b/server/ai/data/progvar_aligned/Gabby/gabby sanchez 5.png\ndeleted file mode 100644\nindex 824309a..0000000\nBinary files a/server/ai/data/progvar_aligned/Gabby/gabby sanchez 5.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Gabby/gabby sanchez 6.png b/server/ai/data/progvar_aligned/Gabby/gabby sanchez 6.png\ndeleted file mode 100644\nindex 68161e8..0000000\nBinary files a/server/ai/data/progvar_aligned/Gabby/gabby sanchez 6.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Ivan/ivan martinez 1.png b/server/ai/data/progvar_aligned/Ivan/ivan martinez 1.png\ndeleted file mode 100644\nindex f5d7375..0000000\nBinary files a/server/ai/data/progvar_aligned/Ivan/ivan martinez 1.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Ivan/ivan martinez 2.png b/server/ai/data/progvar_aligned/Ivan/ivan martinez 2.png\ndeleted file mode 100644\nindex 3acd556..0000000\nBinary files a/server/ai/data/progvar_aligned/Ivan/ivan martinez 2.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Ivan/ivan martinez 3.png b/server/ai/data/progvar_aligned/Ivan/ivan martinez 3.png\ndeleted file mode 100644\nindex d8b95ab..0000000\nBinary files a/server/ai/data/progvar_aligned/Ivan/ivan martinez 3.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Ivan/ivan martinez 4.png b/server/ai/data/progvar_aligned/Ivan/ivan martinez 4.png\ndeleted file mode 100644\nindex 4291313..0000000\nBinary files a/server/ai/data/progvar_aligned/Ivan/ivan martinez 4.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Ivan/ivan martinez 5.png b/server/ai/data/progvar_aligned/Ivan/ivan martinez 5.png\ndeleted file mode 100644\nindex d71badb..0000000\nBinary files a/server/ai/data/progvar_aligned/Ivan/ivan martinez 5.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Ivan/ivan martinez 6.png b/server/ai/data/progvar_aligned/Ivan/ivan martinez 6.png\ndeleted file mode 100644\nindex ae7a2da..0000000\nBinary files a/server/ai/data/progvar_aligned/Ivan/ivan martinez 6.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Jaren/jaren rex 1.png b/server/ai/data/progvar_aligned/Jaren/jaren rex 1.png\ndeleted file mode 100644\nindex ba3aabd..0000000\nBinary files a/server/ai/data/progvar_aligned/Jaren/jaren rex 1.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Jaren/jaren rex 2.png b/server/ai/data/progvar_aligned/Jaren/jaren rex 2.png\ndeleted file mode 100644\nindex 8c3cf17..0000000\nBinary files a/server/ai/data/progvar_aligned/Jaren/jaren rex 2.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Jaren/jaren rex 3.png b/server/ai/data/progvar_aligned/Jaren/jaren rex 3.png\ndeleted file mode 100644\nindex dd118fb..0000000\nBinary files a/server/ai/data/progvar_aligned/Jaren/jaren rex 3.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Jaren/jaren rex 4.png b/server/ai/data/progvar_aligned/Jaren/jaren rex 4.png\ndeleted file mode 100644\nindex d340ece..0000000\nBinary files a/server/ai/data/progvar_aligned/Jaren/jaren rex 4.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Jaren/jaren rex 5.png b/server/ai/data/progvar_aligned/Jaren/jaren rex 5.png\ndeleted file mode 100644\nindex aae8d4e..0000000\nBinary files a/server/ai/data/progvar_aligned/Jaren/jaren rex 5.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Jaren/jaren rex 6.png b/server/ai/data/progvar_aligned/Jaren/jaren rex 6.png\ndeleted file mode 100644\nindex b4a2767..0000000\nBinary files a/server/ai/data/progvar_aligned/Jaren/jaren rex 6.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Jess/jessica sugay 1.png b/server/ai/data/progvar_aligned/Jess/jessica sugay 1.png\ndeleted file mode 100644\nindex 908235f..0000000\nBinary files a/server/ai/data/progvar_aligned/Jess/jessica sugay 1.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Jess/jessica sugay 2.png b/server/ai/data/progvar_aligned/Jess/jessica sugay 2.png\ndeleted file mode 100644\nindex 1a5314a..0000000\nBinary files a/server/ai/data/progvar_aligned/Jess/jessica sugay 2.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Jess/jessica sugay 3.png b/server/ai/data/progvar_aligned/Jess/jessica sugay 3.png\ndeleted file mode 100644\nindex 27bd56d..0000000\nBinary files a/server/ai/data/progvar_aligned/Jess/jessica sugay 3.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Jess/jessica sugay 4.png b/server/ai/data/progvar_aligned/Jess/jessica sugay 4.png\ndeleted file mode 100644\nindex 4f83723..0000000\nBinary files a/server/ai/data/progvar_aligned/Jess/jessica sugay 4.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Jess/jessica sugay 5.png b/server/ai/data/progvar_aligned/Jess/jessica sugay 5.png\ndeleted file mode 100644\nindex ecec8e7..0000000\nBinary files a/server/ai/data/progvar_aligned/Jess/jessica sugay 5.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Jess/jessica sugay 6.png b/server/ai/data/progvar_aligned/Jess/jessica sugay 6.png\ndeleted file mode 100644\nindex ec5d4e1..0000000\nBinary files a/server/ai/data/progvar_aligned/Jess/jessica sugay 6.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Kyle/kyle see 1.png b/server/ai/data/progvar_aligned/Kyle/kyle see 1.png\ndeleted file mode 100644\nindex 9126671..0000000\nBinary files a/server/ai/data/progvar_aligned/Kyle/kyle see 1.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Kyle/kyle see 2.png b/server/ai/data/progvar_aligned/Kyle/kyle see 2.png\ndeleted file mode 100644\nindex 635bda5..0000000\nBinary files a/server/ai/data/progvar_aligned/Kyle/kyle see 2.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Kyle/kyle see 3.png b/server/ai/data/progvar_aligned/Kyle/kyle see 3.png\ndeleted file mode 100644\nindex 5d0297e..0000000\nBinary files a/server/ai/data/progvar_aligned/Kyle/kyle see 3.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Kyle/kyle see 4.png b/server/ai/data/progvar_aligned/Kyle/kyle see 4.png\ndeleted file mode 100644\nindex 0b3f61f..0000000\nBinary files a/server/ai/data/progvar_aligned/Kyle/kyle see 4.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Kyle/kyle see 5.png b/server/ai/data/progvar_aligned/Kyle/kyle see 5.png\ndeleted file mode 100644\nindex ccf3c15..0000000\nBinary files a/server/ai/data/progvar_aligned/Kyle/kyle see 5.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Kyle/kyle see 6.png b/server/ai/data/progvar_aligned/Kyle/kyle see 6.png\ndeleted file mode 100644\nindex 5710143..0000000\nBinary files a/server/ai/data/progvar_aligned/Kyle/kyle see 6.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Luis/luis ligunas 1.png b/server/ai/data/progvar_aligned/Luis/luis ligunas 1.png\ndeleted file mode 100644\nindex 0f670aa..0000000\nBinary files a/server/ai/data/progvar_aligned/Luis/luis ligunas 1.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Luis/luis ligunas 2.png b/server/ai/data/progvar_aligned/Luis/luis ligunas 2.png\ndeleted file mode 100644\nindex c38772b..0000000\nBinary files a/server/ai/data/progvar_aligned/Luis/luis ligunas 2.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Luis/luis ligunas 3.png b/server/ai/data/progvar_aligned/Luis/luis ligunas 3.png\ndeleted file mode 100644\nindex d2f1613..0000000\nBinary files a/server/ai/data/progvar_aligned/Luis/luis ligunas 3.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Luis/luis ligunas 4.png b/server/ai/data/progvar_aligned/Luis/luis ligunas 4.png\ndeleted file mode 100644\nindex 0496112..0000000\nBinary files a/server/ai/data/progvar_aligned/Luis/luis ligunas 4.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Nina/nina sanchez 1.png b/server/ai/data/progvar_aligned/Nina/nina sanchez 1.png\ndeleted file mode 100644\nindex 08127c7..0000000\nBinary files a/server/ai/data/progvar_aligned/Nina/nina sanchez 1.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Nina/nina sanchez 2.png b/server/ai/data/progvar_aligned/Nina/nina sanchez 2.png\ndeleted file mode 100644\nindex b114c6c..0000000\nBinary files a/server/ai/data/progvar_aligned/Nina/nina sanchez 2.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Nina/nina sanchez 3.png b/server/ai/data/progvar_aligned/Nina/nina sanchez 3.png\ndeleted file mode 100644\nindex c8df1b8..0000000\nBinary files a/server/ai/data/progvar_aligned/Nina/nina sanchez 3.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Nina/nina sanchez 4.png b/server/ai/data/progvar_aligned/Nina/nina sanchez 4.png\ndeleted file mode 100644\nindex 2de90a8..0000000\nBinary files a/server/ai/data/progvar_aligned/Nina/nina sanchez 4.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Nina/nina sanchez 5.png b/server/ai/data/progvar_aligned/Nina/nina sanchez 5.png\ndeleted file mode 100644\nindex 67cfc91..0000000\nBinary files a/server/ai/data/progvar_aligned/Nina/nina sanchez 5.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Nina/nina sanchez 6.png b/server/ai/data/progvar_aligned/Nina/nina sanchez 6.png\ndeleted file mode 100644\nindex 8e63cf6..0000000\nBinary files a/server/ai/data/progvar_aligned/Nina/nina sanchez 6.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Rico/rico tiongson 1.png b/server/ai/data/progvar_aligned/Rico/rico tiongson 1.png\ndeleted file mode 100644\nindex 02d9412..0000000\nBinary files a/server/ai/data/progvar_aligned/Rico/rico tiongson 1.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Rico/rico tiongson 2.png b/server/ai/data/progvar_aligned/Rico/rico tiongson 2.png\ndeleted file mode 100644\nindex effe140..0000000\nBinary files a/server/ai/data/progvar_aligned/Rico/rico tiongson 2.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Rico/rico tiongson 3.png b/server/ai/data/progvar_aligned/Rico/rico tiongson 3.png\ndeleted file mode 100644\nindex 6c80258..0000000\nBinary files a/server/ai/data/progvar_aligned/Rico/rico tiongson 3.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Rico/rico tiongson 4.png b/server/ai/data/progvar_aligned/Rico/rico tiongson 4.png\ndeleted file mode 100644\nindex d2b62db..0000000\nBinary files a/server/ai/data/progvar_aligned/Rico/rico tiongson 4.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Rico/rico tiongson 5.png b/server/ai/data/progvar_aligned/Rico/rico tiongson 5.png\ndeleted file mode 100644\nindex 6b5151e..0000000\nBinary files a/server/ai/data/progvar_aligned/Rico/rico tiongson 5.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Rico/rico tiongson 6.png b/server/ai/data/progvar_aligned/Rico/rico tiongson 6.png\ndeleted file mode 100644\nindex 7ac10ac..0000000\nBinary files a/server/ai/data/progvar_aligned/Rico/rico tiongson 6.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Vernon/vernon gutierrez 1.png b/server/ai/data/progvar_aligned/Vernon/vernon gutierrez 1.png\ndeleted file mode 100644\nindex 90b8cf8..0000000\nBinary files a/server/ai/data/progvar_aligned/Vernon/vernon gutierrez 1.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Vernon/vernon gutierrez 2.png b/server/ai/data/progvar_aligned/Vernon/vernon gutierrez 2.png\ndeleted file mode 100644\nindex 2620c38..0000000\nBinary files a/server/ai/data/progvar_aligned/Vernon/vernon gutierrez 2.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Vernon/vernon gutierrez 3.png b/server/ai/data/progvar_aligned/Vernon/vernon gutierrez 3.png\ndeleted file mode 100644\nindex f47f7f3..0000000\nBinary files a/server/ai/data/progvar_aligned/Vernon/vernon gutierrez 3.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Vernon/vernon gutierrez 4.png b/server/ai/data/progvar_aligned/Vernon/vernon gutierrez 4.png\ndeleted file mode 100644\nindex e1d5296..0000000\nBinary files a/server/ai/data/progvar_aligned/Vernon/vernon gutierrez 4.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Vernon/vernon gutierrez 5.png b/server/ai/data/progvar_aligned/Vernon/vernon gutierrez 5.png\ndeleted file mode 100644\nindex 2c13cc8..0000000\nBinary files a/server/ai/data/progvar_aligned/Vernon/vernon gutierrez 5.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/Vernon/vernon gutierrez 6.png b/server/ai/data/progvar_aligned/Vernon/vernon gutierrez 6.png\ndeleted file mode 100644\nindex 8a40ae2..0000000\nBinary files a/server/ai/data/progvar_aligned/Vernon/vernon gutierrez 6.png and /dev/null differ\ndiff --git a/server/ai/data/progvar_aligned/bounding_boxes_92993.txt b/server/ai/data/progvar_aligned/bounding_boxes_92993.txt\ndeleted file mode 100644\nindex 39b47da..0000000\n--- a/server/ai/data/progvar_aligned/bounding_boxes_92993.txt\n+++ /dev/null\n@@ -1,92 +0,0 @@\n-data/progvar_aligned/Aemiel/aemielvin loremia 4.png 3 0 240 277\n-data/progvar_aligned/Aemiel/aemielvin loremia 6.png 0 5 86 100\n-data/progvar_aligned/Aemiel/aemielvin loremia 1.png 5 46 148 208\n-data/progvar_aligned/Aemiel/aemielvin loremia 5.png 13 46 169 225\n-data/progvar_aligned/Aemiel/aemielvin loremia 3.png 23 16 149 162\n-data/progvar_aligned/Aemiel/aemielvin loremia 2.png 0 5 99 116\n-data/progvar_aligned/Aldrich/aldrich asuncion 2.png 46 114 435 620\n-data/progvar_aligned/Aldrich/aldrich asuncion 5.png 2 0 90 98\n-data/progvar_aligned/Aldrich/aldrich asuncion 1.png 18 4 169 189\n-data/progvar_aligned/Aldrich/aldrich asuncion 6.png 18 1 190 223\n-data/progvar_aligned/Aldrich/aldrich asuncion 3.png 38 17 218 238\n-data/progvar_aligned/Aldrich/aldrich asuncion 4.png 4 0 138 145\n-data/progvar_aligned/Andre/andre tan 4.png 287 295 868 1047\n-data/progvar_aligned/Andre/andre tan 1.png 30 68 325 440\n-data/progvar_aligned/Andre/andre tan 2.png 144 87 492 544\n-data/progvar_aligned/Andre/andre tan 3.png 26 32 198 233\n-data/progvar_aligned/Andre/andre tan 6.png 219 117 510 510\n-data/progvar_aligned/Andre/andre tan 5.png 253 281 777 990\n-data/progvar_aligned/Brian/brian guadalupe 1.png 67 53 284 324\n-data/progvar_aligned/Brian/brian guadalupe 4.png 23 26 180 221\n-data/progvar_aligned/Brian/brian guadalupe 3.png 17 6 169 187\n-data/progvar_aligned/Brian/brian guadalupe 2.png 38 29 195 223\n-data/progvar_aligned/DavidC/david cuajunco 2.png 22 20 167 189\n-data/progvar_aligned/DavidC/david cuajunco 6.png 0 14 198 267\n-data/progvar_aligned/DavidC/david cuajunco 4.png 39 2 158 143\n-data/progvar_aligned/DavidC/david cuajunco 5.png 13 6 121 131\n-data/progvar_aligned/DavidC/david cuajunco 3.png 35 27 206 226\n-data/progvar_aligned/DavidC/david cuajunco 1.png 31 11 166 179\n-data/progvar_aligned/DavidD/david diy 4.png 20 10 119 130\n-data/progvar_aligned/DavidD/david diy 2.png 0 12 98 123\n-data/progvar_aligned/DavidD/david diy 1.png 0 15 95 121\n-data/progvar_aligned/DavidD/david diy 3.png 26 26 121 160\n-data/progvar_aligned/DavidD/david diy 6.png 0 14 92 115\n-data/progvar_aligned/DavidD/david diy 5.png 46 46 248 296\n-data/progvar_aligned/Deanne/deanne pascual 4.png 34 28 243 277\n-data/progvar_aligned/Deanne/deanne pascual 1.png 28 38 237 301\n-data/progvar_aligned/Deanne/deanne pascual 2.png 32 30 216 254\n-data/progvar_aligned/Deanne/deanne pascual 6.png 21 5 173 184\n-data/progvar_aligned/Deanne/deanne pascual 5.png 6 16 128 161\n-data/progvar_aligned/Deanne/deanne pascual 3.png 28 0 130 113\n-data/progvar_aligned/Gabby/gabby sanchez 5.png 0 33 135 198\n-data/progvar_aligned/Gabby/gabby sanchez 2.png 47 82 278 387\n-data/progvar_aligned/Gabby/gabby sanchez 6.png 17 27 171 213\n-data/progvar_aligned/Gabby/gabby sanchez 3.png 30 58 236 328\n-data/progvar_aligned/Gabby/gabby sanchez 1.png 12 7 91 94\n-data/progvar_aligned/Gabby/gabby sanchez 4.png 23 20 169 200\n-data/progvar_aligned/Ivan/ivan martinez 1.png 14 109 290 436\n-data/progvar_aligned/Ivan/ivan martinez 4.png 5 9 116 139\n-data/progvar_aligned/Ivan/ivan martinez 3.png 9 4 103 119\n-data/progvar_aligned/Ivan/ivan martinez 2.png 26 36 235 290\n-data/progvar_aligned/Ivan/ivan martinez 5.png 35 20 214 247\n-data/progvar_aligned/Ivan/ivan martinez 6.png 0 9 117 160\n-data/progvar_aligned/Jaren/jaren rex 6.png 66 102 394 511\n-data/progvar_aligned/Jaren/jaren rex 4.png 35 25 167 185\n-data/progvar_aligned/Jaren/jaren rex 5.png 40 71 253 324\n-data/progvar_aligned/Jaren/jaren rex 1.png 40 107 288 418\n-data/progvar_aligned/Jaren/jaren rex 3.png 91 114 362 461\n-data/progvar_aligned/Jaren/jaren rex 2.png 13 94 222 347\n-data/progvar_aligned/Jess/jessica sugay 4.png 19 38 318 414\n-data/progvar_aligned/Jess/jessica sugay 1.png 68 49 361 433\n-data/progvar_aligned/Jess/jessica sugay 3.png 29 3 195 217\n-data/progvar_aligned/Jess/jessica sugay 6.png 97 78 294 335\n-data/progvar_aligned/Jess/jessica sugay 2.png 20 21 293 366\n-data/progvar_aligned/Jess/jessica sugay 5.png 8 13 194 239\n-data/progvar_aligned/Kyle/kyle see 6.png 1 13 81 101\n-data/progvar_aligned/Kyle/kyle see 1.png 21 12 129 146\n-data/progvar_aligned/Kyle/kyle see 2.png 22 15 126 138\n-data/progvar_aligned/Kyle/kyle see 4.png 40 5 124 100\n-data/progvar_aligned/Kyle/kyle see 5.png 0 14 119 163\n-data/progvar_aligned/Kyle/kyle see 3.png 11 83 212 328\n-data/progvar_aligned/Luis/luis ligunas 4.png 30 52 230 260\n-data/progvar_aligned/Luis/luis ligunas 1.png 23 21 140 160\n-data/progvar_aligned/Luis/luis ligunas 3.png 9 14 112 135\n-data/progvar_aligned/Luis/luis ligunas 2.png 15 10 127 142\n-data/progvar_aligned/Nina/nina sanchez 2.png 91 60 312 311\n-data/progvar_aligned/Nina/nina sanchez 3.png 80 15 238 206\n-data/progvar_aligned/Nina/nina sanchez 1.png 12 48 211 273\n-data/progvar_aligned/Nina/nina sanchez 4.png 86 65 324 355\n-data/progvar_aligned/Nina/nina sanchez 5.png 136 27 331 252\n-data/progvar_aligned/Nina/nina sanchez 6.png 53 33 247 263\n-data/progvar_aligned/Rico/rico tiongson 3.png 78 81 270 316\n-data/progvar_aligned/Rico/rico tiongson 4.png 16 28 120 165\n-data/progvar_aligned/Rico/rico tiongson 1.png 47 25 179 208\n-data/progvar_aligned/Rico/rico tiongson 2.png 15 16 126 151\n-data/progvar_aligned/Rico/rico tiongson 5.png 40 122 294 420\n-data/progvar_aligned/Rico/rico tiongson 6.png 14 19 131 157\n-data/progvar_aligned/Vernon/vernon gutierrez 5.png 71 22 231 211\n-data/progvar_aligned/Vernon/vernon gutierrez 3.png 12 113 283 465\n-data/progvar_aligned/Vernon/vernon gutierrez 4.png 18 24 166 195\n-data/progvar_aligned/Vernon/vernon gutierrez 2.png 9 21 103 126\n-data/progvar_aligned/Vernon/vernon gutierrez 6.png 20 58 252 325\n-data/progvar_aligned/Vernon/vernon gutierrez 1.png 15 39 174 227\ndiff --git a/server/ai/data/progvar_aligned/revision_info.txt b/server/ai/data/progvar_aligned/revision_info.txt\ndeleted file mode 100644\nindex 3d7cf4d..0000000\n--- a/server/ai/data/progvar_aligned/revision_info.txt\n+++ /dev/null\n@@ -1,5 +0,0 @@\n-arguments: facenet/align/align_dataset_mtcnn.py data/progvar_raw data/progvar_aligned --gpu_memory_fraction 0.68\n---------------------\n-git hash: b\'6bdbcfa3bd38b4e8a13702099a7a31af2ba7e879\'\n---------------------\n-b\'diff --git a/server/ai/Classifier Training + Prediction .ipynb b/server/ai/Classifier Training + Prediction .ipynb\\ndeleted file mode 100644\\nindex 5e9f6c6..0000000\\n--- a/server/ai/Classifier Training + Prediction .ipynb\\t\\n+++ /dev/null\\n@@ -1,166 +0,0 @@\\n-{\\n- "cells": [\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 1,\\n-   "metadata": {\\n-    "collapsed": true\\n-   },\\n-   "outputs": [],\\n-   "source": [\\n-    "import cv2, cv2.face\\\\n",\\n-    "import os, os.path\\\\n",\\n-    "import numpy as np"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 2,\\n-   "metadata": {\\n-    "collapsed": false\\n-   },\\n-   "outputs": [],\\n-   "source": [\\n-    "import train"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 3,\\n-   "metadata": {\\n-    "collapsed": false,\\n-    "scrolled": true\\n-   },\\n-   "outputs": [\\n-    {\\n-     "name": "stdout",\\n-     "output_type": "stream",\\n-     "text": [\\n-      "Accuracy: 100.00000%\\\\n",\\n-      "Collected 75 images [10 labels]\\\\n",\\n-      "Saved classifier /home/rico/Git/Fresent/server/ai/classifiers/Charles_Taylor.xml\\\\n",\\n-      "Saved classifier /home/rico/Git/Fresent/server/ai/classifiers/Jesse_Jackson.xml\\\\n",\\n-      "Saved classifier /home/rico/Git/Fresent/server/ai/classifiers/Hosni_Mubarak.xml\\\\n",\\n-      "Saved classifier /home/rico/Git/Fresent/server/ai/classifiers/George_Clooney.xml\\\\n",\\n-      "Saved classifier /home/rico/Git/Fresent/server/ai/classifiers/Hugh_Grant.xml\\\\n",\\n-      "Saved classifier /home/rico/Git/Fresent/server/ai/classifiers/Jeong_Se-hyun.xml\\\\n",\\n-      "Saved classifier /home/rico/Git/Fresent/server/ai/classifiers/Heizo_Takenaka.xml\\\\n",\\n-      "Saved classifier /home/rico/Git/Fresent/server/ai/classifiers/Aaron_Peirsol.xml\\\\n",\\n-      "Saved classifier /home/rico/Git/Fresent/server/ai/classifiers/Fernando_Gonzalez.xml\\\\n",\\n-      "Saved classifier /home/rico/Git/Fresent/server/ai/classifiers/Colin_Farrell.xml\\\\n"\\n-     ]\\n-    }\\n-   ],\\n-   "source": [\\n-    "train.generate_classifiers(\\\'data/sample_training\\\', \\\'classifiers\\\', None)"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 4,\\n-   "metadata": {\\n-    "collapsed": false\\n-   },\\n-   "outputs": [\\n-    {\\n-     "name": "stdout",\\n-     "output_type": "stream",\\n-     "text": [\\n-      "(True, 70.33203017168863)\\\\n",\\n-      "(False, 64.02631180994958)\\\\n"\\n-     ]\\n-    }\\n-   ],\\n-   "source": [\\n-    "# Test matching with some test data\\\\n",\\n-    "\\\\n",\\n-    "import predict, util\\\\n",\\n-    "\\\\n",\\n-    "hosni = util.load_grayscale_image(\\\'data/sample_testing/Hosni_Mubarak/Hosni_Mubarak_0009.png\\\')\\\\n",\\n-    "aaron = util.load_grayscale_image(\\\'data/sample_testing/Aaron_Peirsol/Aaron_Peirsol_0004.png\\\')\\\\n",\\n-    "\\\\n",\\n-    "import cv2\\\\n",\\n-    "cv2.imshow(\\\'Hello\\\', aaron)\\\\n",\\n-    "\\\\n",\\n-    "print(predict.match_classifier(\\\'classifiers/Hosni_Mubarak.xml\\\', hosni))\\\\n",\\n-    "print(predict.match_classifier(\\\'classifiers/Hosni_Mubarak.xml\\\', aaron))"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 7,\\n-   "metadata": {\\n-    "collapsed": false\\n-   },\\n-   "outputs": [\\n-    {\\n-     "name": "stdout",\\n-     "output_type": "stream",\\n-     "text": [\\n-      "Accuracy: 100.00000%\\\\n",\\n-      "Expected=True (True, 70.33203017168863)\\\\n",\\n-      "Expected=True (False, 66.9695790300998)\\\\n",\\n-      "Expected=True (False, 64.02631180994958)\\\\n",\\n-      "Expected=True (True, 62.252336352937334)\\\\n",\\n-      "Expected=True (False, 55.98307131663556)\\\\n",\\n-      "Expected=True (True, 58.443145513715066)\\\\n",\\n-      "Expected=True (True, 58.194282662587064)\\\\n",\\n-      "Expected=True (False, 61.83141922223049)\\\\n",\\n-      "Expected=True (True, 60.659852760896726)\\\\n",\\n-      "Expected=True (True, 69.14819846258747)\\\\n"\\n-     ]\\n-    }\\n-   ],\\n-   "source": [\\n-    "# test all labels\\\\n",\\n-    "import util\\\\n",\\n-    "images, labels = util.get_images_and_labels(\\\'data/sample_testing\\\')\\\\n",\\n-    "\\\\n",\\n-    "correct = 0\\\\n",\\n-    "total = 0\\\\n",\\n-    "\\\\n",\\n-    "for image, label in zip(images, labels):\\\\n",\\n-    "    \\\\n",\\n-    "    is_match, conf = predict.match_classifier(\\\'classifiers/\\\' + label + \\\'.xml\\\', image)\\\\n",\\n-    "    print(\\\'Match:\\\', is_match, conf)\\\\n",\\n-    "    \\\\n",\\n-    "    if is_match:\\\\n",\\n-    "        correct += 1\\\\n",\\n-    "    total += 1\\\\n",\\n-    "\\\\n",\\n-    "print(\\\'Accuracy: %.5f\\\' % (100 * correct / max(1, total)))\\\\n",\\n-    "    "\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": null,\\n-   "metadata": {\\n-    "collapsed": true\\n-   },\\n-   "outputs": [],\\n-   "source": []\\n-  }\\n- ],\\n- "metadata": {\\n-  "kernelspec": {\\n-   "display_name": "Tensorflow",\\n-   "language": "python",\\n-   "name": "tensorflow"\\n-  },\\n-  "language_info": {\\n-   "codemirror_mode": {\\n-    "name": "ipython",\\n-    "version": 3\\n-   },\\n-   "file_extension": ".py",\\n-   "mimetype": "text/x-python",\\n-   "name": "python",\\n-   "nbconvert_exporter": "python",\\n-   "pygments_lexer": "ipython3",\\n-   "version": "3.5.2"\\n-  }\\n- },\\n- "nbformat": 4,\\n- "nbformat_minor": 2\\n-}\\ndiff --git a/server/ai/Face Recognition - Classifier Comparison.ipynb b/server/ai/Face Recognition - Classifier Comparison.ipynb\\ndeleted file mode 100644\\nindex 1faf78c..0000000\\n--- a/server/ai/Face Recognition - Classifier Comparison.ipynb\\t\\n+++ /dev/null\\n@@ -1,619 +0,0 @@\\n-{\\n- "cells": [\\n-  {\\n-   "cell_type": "markdown",\\n-   "metadata": {},\\n-   "source": [\\n-    "# Face Recognition - Generate Eigenface Classifiers\\\\n",\\n-    "\\\\n",\\n-    "This notebook tests face detection and recognition from sample images"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 1,\\n-   "metadata": {\\n-    "collapsed": true\\n-   },\\n-   "outputs": [],\\n-   "source": [\\n-    "import cv2, cv2.face\\\\n",\\n-    "import os, os.path\\\\n",\\n-    "import numpy as np\\\\n",\\n-    "from PIL import Image"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 2,\\n-   "metadata": {\\n-    "collapsed": true\\n-   },\\n-   "outputs": [],\\n-   "source": [\\n-    "# constants\\\\n",\\n-    "CASCADE_PATH = \\\'./data/\\\'\\\\n",\\n-    "CASCADE_NAME = \\\'haarcascade_frontalface_default.xml\\\'\\\\n",\\n-    "SAMPLE_TRAINING = \\\'./data/sample_training/\\\'\\\\n",\\n-    "SAMPLE_TESTING = \\\'./data/sample_testing/\\\'"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 3,\\n-   "metadata": {\\n-    "collapsed": true\\n-   },\\n-   "outputs": [],\\n-   "source": [\\n-    "#vSAMPLE_TRAINING = \\\'/home/rico/datasets/lfw/raw/\\\'"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 4,\\n-   "metadata": {\\n-    "collapsed": false\\n-   },\\n-   "outputs": [],\\n-   "source": [\\n-    "# Viola-Jones classifier for Haar feature extraction\\\\n",\\n-    "cascader_file = os.path.join(CASCADE_PATH, CASCADE_NAME)\\\\n",\\n-    "cascader = cv2.CascadeClassifier(cascader_file)\\\\n",\\n-    "assert(not cascader.empty())\\\\n",\\n-    "\\\\n",\\n-    "cascader_kwargs = { # setup detection args here\\\\n",\\n-    "    \\\'scaleFactor\\\': 1.1,\\\\n",\\n-    "    \\\'minNeighbors\\\': 2,\\\\n",\\n-    "    \\\'flags\\\': 2\\\\n",\\n-    "}"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 5,\\n-   "metadata": {\\n-    "collapsed": true\\n-   },\\n-   "outputs": [],\\n-   "source": [\\n-    "from util import get_images_and_labels"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 6,\\n-   "metadata": {\\n-    "collapsed": false\\n-   },\\n-   "outputs": [\\n-    {\\n-     "name": "stdout",\\n-     "output_type": "stream",\\n-     "text": [\\n-      "Hosni_Mubarak\\\\n",\\n-      "\\\\tHosni_Mubarak_0007.png [1 face]\\\\n",\\n-      "\\\\tHosni_Mubarak_0003.png [1 face]\\\\n",\\n-      "\\\\tHosni_Mubarak_0004.png [1 face]\\\\n",\\n-      "\\\\tHosni_Mubarak_0008.png [1 face]\\\\n",\\n-      "\\\\tHosni_Mubarak_0005.png [1 face]\\\\n",\\n-      "\\\\tHosni_Mubarak_0001.png [1 face]\\\\n",\\n-      "\\\\tHosni_Mubarak_0006.png [1 face]\\\\n",\\n-      "\\\\tHosni_Mubarak_0002.png [1 face]\\\\n",\\n-      "[Added 8 images]\\\\n",\\n-      "Jeong_Se-hyun\\\\n",\\n-      "\\\\tJeong_Se-hyun_0007.png [1 face]\\\\n",\\n-      "\\\\tJeong_Se-hyun_0001.png [1 face]\\\\n",\\n-      "\\\\tJeong_Se-hyun_0008.png [1 face]\\\\n",\\n-      "\\\\tJeong_Se-hyun_0003.png [1 face]\\\\n",\\n-      "\\\\tJeong_Se-hyun_0004.png [1 face]\\\\n",\\n-      "\\\\tJeong_Se-hyun_0002.png [1 face]\\\\n",\\n-      "\\\\tJeong_Se-hyun_0005.png [1 face]\\\\n",\\n-      "\\\\tJeong_Se-hyun_0006.png [1 face]\\\\n",\\n-      "[Added 16 images]\\\\n",\\n-      "Aaron_Peirsol\\\\n",\\n-      "\\\\tAaron_Peirsol_0003.png [1 face]\\\\n",\\n-      "\\\\tAaron_Peirsol_0001.png [1 face]\\\\n",\\n-      "\\\\tAaron_Peirsol_0002.png [1 face]\\\\n",\\n-      "[Added 19 images]\\\\n",\\n-      "Heizo_Takenaka\\\\n",\\n-      "\\\\tHeizo_Takenaka_0002.png [1 face]\\\\n",\\n-      "\\\\tHeizo_Takenaka_0007.png [1 face]\\\\n",\\n-      "\\\\tHeizo_Takenaka_0001.png [1 face]\\\\n",\\n-      "\\\\tHeizo_Takenaka_0006.png [1 face]\\\\n",\\n-      "\\\\tHeizo_Takenaka_0004.png [1 face]\\\\n",\\n-      "\\\\tHeizo_Takenaka_0008.png [1 face]\\\\n",\\n-      "\\\\tHeizo_Takenaka_0003.png [1 face]\\\\n",\\n-      "\\\\tHeizo_Takenaka_0005.png [1 face]\\\\n",\\n-      "[Added 27 images]\\\\n",\\n-      "Jesse_Jackson\\\\n",\\n-      "\\\\tJesse_Jackson_0001.png [1 face]\\\\n",\\n-      "\\\\tJesse_Jackson_0007.png [1 face]\\\\n",\\n-      "\\\\tJesse_Jackson_0004.png [1 face]\\\\n",\\n-      "\\\\tJesse_Jackson_0002.png [1 face]\\\\n",\\n-      "\\\\tJesse_Jackson_0003.png [1 face]\\\\n",\\n-      "\\\\tJesse_Jackson_0008.png [1 face]\\\\n",\\n-      "\\\\tJesse_Jackson_0006.png [1 face]\\\\n",\\n-      "\\\\tJesse_Jackson_0005.png [1 face]\\\\n",\\n-      "[Added 35 images]\\\\n",\\n-      "Hugh_Grant\\\\n",\\n-      "\\\\tHugh_Grant_0002.png [1 face]\\\\n",\\n-      "\\\\tHugh_Grant_0006.png [1 face]\\\\n",\\n-      "\\\\tHugh_Grant_0004.png [1 face]\\\\n",\\n-      "\\\\tHugh_Grant_0008.png [1 face]\\\\n",\\n-      "\\\\tHugh_Grant_0001.png [1 face]\\\\n",\\n-      "\\\\tHugh_Grant_0007.png [1 face]\\\\n",\\n-      "\\\\tHugh_Grant_0003.png [1 face]\\\\n",\\n-      "\\\\tHugh_Grant_0005.png [1 face]\\\\n",\\n-      "[Added 43 images]\\\\n",\\n-      "Fernando_Gonzalez\\\\n",\\n-      "\\\\tFernando_Gonzalez_0006.png [1 face]\\\\n",\\n-      "\\\\tFernando_Gonzalez_0007.png [1 face]\\\\n",\\n-      "\\\\tFernando_Gonzalez_0004.png [1 face]\\\\n",\\n-      "\\\\tFernando_Gonzalez_0002.png [1 face]\\\\n",\\n-      "\\\\tFernando_Gonzalez_0003.png [1 face]\\\\n",\\n-      "\\\\tFernando_Gonzalez_0001.png [1 face]\\\\n",\\n-      "\\\\tFernando_Gonzalez_0005.png [1 face]\\\\n",\\n-      "\\\\tFernando_Gonzalez_0008.png [1 face]\\\\n",\\n-      "[Added 51 images]\\\\n",\\n-      "George_Clooney\\\\n",\\n-      "\\\\tGeorge_Clooney_0007.png [1 face]\\\\n",\\n-      "\\\\tGeorge_Clooney_0001.png [1 face]\\\\n",\\n-      "\\\\tGeorge_Clooney_0003.png [1 face]\\\\n",\\n-      "\\\\tGeorge_Clooney_0006.png [1 face]\\\\n",\\n-      "\\\\tGeorge_Clooney_0005.png [1 face]\\\\n",\\n-      "\\\\tGeorge_Clooney_0008.png [1 face]\\\\n",\\n-      "\\\\tGeorge_Clooney_0004.png [1 face]\\\\n",\\n-      "\\\\tGeorge_Clooney_0002.png [1 face]\\\\n",\\n-      "[Added 59 images]\\\\n",\\n-      "Colin_Farrell\\\\n",\\n-      "\\\\tColin_Farrell_0007.png [1 face]\\\\n",\\n-      "\\\\tColin_Farrell_0002.png [1 face]\\\\n",\\n-      "\\\\tColin_Farrell_0006.png [1 face]\\\\n",\\n-      "\\\\tColin_Farrell_0003.png [1 face]\\\\n",\\n-      "\\\\tColin_Farrell_0004.png [1 face]\\\\n",\\n-      "\\\\tColin_Farrell_0008.png [1 face]\\\\n",\\n-      "\\\\tColin_Farrell_0005.png [1 face]\\\\n",\\n-      "\\\\tColin_Farrell_0001.png [1 face]\\\\n",\\n-      "[Added 67 images]\\\\n",\\n-      "Charles_Taylor\\\\n",\\n-      "\\\\tCharles_Taylor_0002.png [1 face]\\\\n",\\n-      "\\\\tCharles_Taylor_0005.png [1 face]\\\\n",\\n-      "\\\\tCharles_Taylor_0004.png [1 face]\\\\n",\\n-      "\\\\tCharles_Taylor_0001.png [1 face]\\\\n",\\n-      "\\\\tCharles_Taylor_0007.png [1 face]\\\\n",\\n-      "\\\\tCharles_Taylor_0003.png [1 face]\\\\n",\\n-      "\\\\tCharles_Taylor_0006.png [1 face]\\\\n",\\n-      "\\\\tCharles_Taylor_0008.png [1 face]\\\\n",\\n-      "[Added 75 images]\\\\n"\\n-     ]\\n-    }\\n-   ],\\n-   "source": [\\n-    "# setup training set\\\\n",\\n-    "training_set = get_images_and_labels(SAMPLE_TRAINING,\\\\n",\\n-    "                                    cascader=None,\\\\n",\\n-    "                                    debug=True,\\\\n",\\n-    "                                    debug_accuracy=False)"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 7,\\n-   "metadata": {\\n-    "collapsed": false\\n-   },\\n-   "outputs": [\\n-    {\\n-     "name": "stdout",\\n-     "output_type": "stream",\\n-     "text": [\\n-      "Accuracy: 100.00000%\\\\n",\\n-      "Accuracy: 100.00000%\\\\n"\\n-     ]\\n-    }\\n-   ],\\n-   "source": [\\n-    "# setup testing set\\\\n",\\n-    "testing_set_cascade = get_images_and_labels(SAMPLE_TESTING,\\\\n",\\n-    "                                    cascader=cascader,\\\\n",\\n-    "                                    debug=False,\\\\n",\\n-    "                                    debug_faces=True,\\\\n",\\n-    "                                    debug_accuracy=True)\\\\n",\\n-    "\\\\n",\\n-    "testing_set= get_images_and_labels(SAMPLE_TESTING,\\\\n",\\n-    "                                    cascader=None,\\\\n",\\n-    "                                    debug=False,\\\\n",\\n-    "                                    debug_faces=True,\\\\n",\\n-    "                                    debug_accuracy=True)\\\\n"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 8,\\n-   "metadata": {\\n-    "collapsed": false\\n-   },\\n-   "outputs": [],\\n-   "source": [\\n-    "# setup labels\\\\n",\\n-    "label_dict = {}\\\\n",\\n-    "label_dict_inv = {}\\\\n",\\n-    "\\\\n",\\n-    "for label in training_set[1]:\\\\n",\\n-    "    if label not in label_dict:\\\\n",\\n-    "        label_dict_inv[len(label_dict)] = label\\\\n",\\n-    "        label_dict[label] = len(label_dict)\\\\n",\\n-    "        "\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 9,\\n-   "metadata": {\\n-    "collapsed": false\\n-   },\\n-   "outputs": [],\\n-   "source": [\\n-    "def perform_training(recognizer):\\\\n",\\n-    "    images, raw_labels = training_set\\\\n",\\n-    "    labels = [label_dict[label] for label in raw_labels]\\\\n",\\n-    "    print(labels)\\\\n",\\n-    "    recognizer.train(images, np.array(labels))\\\\n",\\n-    "    print(\\\'Trained %d images\\\\\\\\n\\\' % len(images))"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 10,\\n-   "metadata": {\\n-    "collapsed": false\\n-   },\\n-   "outputs": [],\\n-   "source": [\\n-    "def perform_testing(recognizer, testing_set=testing_set):\\\\n",\\n-    "    \\\\n",\\n-    "    images, labels = testing_set\\\\n",\\n-    "    \\\\n",\\n-    "    print(\\\'Performing %d tests\\\\\\\\n\\\' % len(images))\\\\n",\\n-    "\\\\n",\\n-    "    correct = 0\\\\n",\\n-    "    total = 0\\\\n",\\n-    "\\\\n",\\n-    "    for image, expected in zip(images, labels):\\\\n",\\n-    "        \\\\n",\\n-    "        if expected not in label_dict:\\\\n",\\n-    "            print(\\\'No face found for %s\\\' % expected)\\\\n",\\n-    "            \\\\n",\\n-    "        else:\\\\n",\\n-    "            eid = label_dict[expected]\\\\n",\\n-    "            lid, confidence = recognizer.predict(image)\\\\n",\\n-    "            \\\\n",\\n-    "            if lid in label_dict_inv:\\\\n",\\n-    "                \\\\n",\\n-    "                actual = label_dict_inv[lid]\\\\n",\\n-    "                                        \\\\n",\\n-    "                if eid == lid:\\\\n",\\n-    "                    print(\\\'%s is correctly recognized with confidence %.10f\\\' % (expected, confidence))\\\\n",\\n-    "                    correct += 1\\\\n",\\n-    "                                        \\\\n",\\n-    "                else:\\\\n",\\n-    "                    print(\\\'%s incorrect (recognized as %s with confidence %.10f)\\\' % (expected, actual, confidence))\\\\n",\\n-    "                    \\\\n",\\n-    "            else:\\\\n",\\n-    "                print(\\\'No face found for %s\\\' % expected)\\\\n",\\n-    "                \\\\n",\\n-    "        total += 1\\\\n",\\n-    "\\\\n",\\n-    "    print()\\\\n",\\n-    "    print(\\\'Accuracy: %.2f%%\\\' % (100 * (correct / max(1, total))))\\\\n",\\n-    "    print(\\\'Correct:  %d\\\' % correct)\\\\n",\\n-    "    print(\\\'Wrong:    %d\\\' % (total - correct))"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 11,\\n-   "metadata": {\\n-    "collapsed": false\\n-   },\\n-   "outputs": [\\n-    {\\n-     "name": "stdout",\\n-     "output_type": "stream",\\n-     "text": [\\n-      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9]\\\\n",\\n-      "Trained 75 images\\\\n",\\n-      "\\\\n",\\n-      "0 0 70.33203017168863\\\\n",\\n-      "1 4 66.9695790300998\\\\n",\\n-      "2 8 64.02631180994958\\\\n",\\n-      "3 3 62.252336352937334\\\\n",\\n-      "4 5 55.98307131663556\\\\n",\\n-      "5 5 58.443145513715066\\\\n",\\n-      "6 6 58.194282662587064\\\\n",\\n-      "7 1 61.83141922223049\\\\n",\\n-      "8 8 60.659852760896726\\\\n",\\n-      "9 9 69.14819846258747\\\\n",\\n-      "60.0 % Accuracy\\\\n"\\n-     ]\\n-    }\\n-   ],\\n-   "source": [\\n-    "reco = cv2.face.createLBPHFaceRecognizer()\\\\n",\\n-    "perform_training(reco)\\\\n",\\n-    "ims, ls = testing_set\\\\n",\\n-    "cor = 0\\\\n",\\n-    "tot = 0\\\\n",\\n-    "for im, l in zip(ims,ls):\\\\n",\\n-    "    label = label_dict[l]\\\\n",\\n-    "    inf, conf = reco.predict(im)\\\\n",\\n-    "    print(label, inf, conf)\\\\n",\\n-    "    if (label == inf):\\\\n",\\n-    "        cor += 1\\\\n",\\n-    "    tot += 1\\\\n",\\n-    "print(100*cor/tot,\\\'% Accuracy\\\')"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "markdown",\\n-   "metadata": {},\\n-   "source": [\\n-    "# 1. EigenFaces"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 12,\\n-   "metadata": {\\n-    "collapsed": false\\n-   },\\n-   "outputs": [],\\n-   "source": [\\n-    "# face recognizer\\\\n",\\n-    "recognizer = cv2.face.createEigenFaceRecognizer()"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 13,\\n-   "metadata": {\\n-    "collapsed": false,\\n-    "scrolled": true\\n-   },\\n-   "outputs": [\\n-    {\\n-     "name": "stdout",\\n-     "output_type": "stream",\\n-     "text": [\\n-      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9]\\\\n",\\n-      "Trained 75 images\\\\n",\\n-      "\\\\n",\\n-      "CPU times: user 532 ms, sys: 48 ms, total: 580 ms\\\\n",\\n-      "Wall time: 579 ms\\\\n"\\n-     ]\\n-    }\\n-   ],\\n-   "source": [\\n-    "%%time\\\\n",\\n-    "# Perform the training\\\\n",\\n-    "perform_training(recognizer)"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 14,\\n-   "metadata": {\\n-    "collapsed": false\\n-   },\\n-   "outputs": [\\n-    {\\n-     "name": "stdout",\\n-     "output_type": "stream",\\n-     "text": [\\n-      "Performing 10 tests\\\\n",\\n-      "\\\\n",\\n-      "Hosni_Mubarak incorrect (recognized as Jeong_Se-hyun with confidence 7708.8797264715)\\\\n",\\n-      "Jeong_Se-hyun incorrect (recognized as Jesse_Jackson with confidence 9191.3998485021)\\\\n",\\n-      "Aaron_Peirsol incorrect (recognized as Jeong_Se-hyun with confidence 7686.4538475870)\\\\n",\\n-      "Heizo_Takenaka is correctly recognized with confidence 7592.1110518190\\\\n",\\n-      "Jesse_Jackson incorrect (recognized as George_Clooney with confidence 7535.3358054781)\\\\n",\\n-      "Hugh_Grant is correctly recognized with confidence 7144.1526959103\\\\n",\\n-      "Fernando_Gonzalez is correctly recognized with confidence 7184.3745207685\\\\n",\\n-      "George_Clooney is correctly recognized with confidence 8396.7570350231\\\\n",\\n-      "Colin_Farrell incorrect (recognized as Hugh_Grant with confidence 7856.0370864173)\\\\n",\\n-      "Charles_Taylor incorrect (recognized as Fernando_Gonzalez with confidence 9496.5626098884)\\\\n",\\n-      "\\\\n",\\n-      "Accuracy: 40.00%\\\\n",\\n-      "Correct:  4\\\\n",\\n-      "Wrong:    6\\\\n"\\n-     ]\\n-    }\\n-   ],\\n-   "source": [\\n-    "perform_testing(recognizer)"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "markdown",\\n-   "metadata": {},\\n-   "source": [\\n-    "# 2. FisherFaces"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 15,\\n-   "metadata": {\\n-    "collapsed": true\\n-   },\\n-   "outputs": [],\\n-   "source": [\\n-    "# face recognizer\\\\n",\\n-    "recognizer = cv2.face.createFisherFaceRecognizer()"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 16,\\n-   "metadata": {\\n-    "collapsed": false\\n-   },\\n-   "outputs": [\\n-    {\\n-     "name": "stdout",\\n-     "output_type": "stream",\\n-     "text": [\\n-      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9]\\\\n",\\n-      "Trained 75 images\\\\n",\\n-      "\\\\n",\\n-      "CPU times: user 492 ms, sys: 16 ms, total: 508 ms\\\\n",\\n-      "Wall time: 506 ms\\\\n"\\n-     ]\\n-    }\\n-   ],\\n-   "source": [\\n-    "%%time\\\\n",\\n-    "perform_training(recognizer)"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 17,\\n-   "metadata": {\\n-    "collapsed": false\\n-   },\\n-   "outputs": [\\n-    {\\n-     "name": "stdout",\\n-     "output_type": "stream",\\n-     "text": [\\n-      "Performing 10 tests\\\\n",\\n-      "\\\\n",\\n-      "Hosni_Mubarak incorrect (recognized as George_Clooney with confidence 1415.5985222224)\\\\n",\\n-      "Jeong_Se-hyun incorrect (recognized as Colin_Farrell with confidence 1941.4372785408)\\\\n",\\n-      "Aaron_Peirsol incorrect (recognized as Hosni_Mubarak with confidence 1495.4150848578)\\\\n",\\n-      "Heizo_Takenaka incorrect (recognized as Colin_Farrell with confidence 2170.6659331031)\\\\n",\\n-      "Jesse_Jackson incorrect (recognized as Hugh_Grant with confidence 1476.5334439179)\\\\n",\\n-      "Hugh_Grant is correctly recognized with confidence 1683.8350626277\\\\n",\\n-      "Fernando_Gonzalez is correctly recognized with confidence 1736.9916732560\\\\n",\\n-      "George_Clooney is correctly recognized with confidence 1638.8801908796\\\\n",\\n-      "Colin_Farrell incorrect (recognized as Fernando_Gonzalez with confidence 1593.3159287082)\\\\n",\\n-      "Charles_Taylor incorrect (recognized as Hosni_Mubarak with confidence 1666.5036180065)\\\\n",\\n-      "\\\\n",\\n-      "Accuracy: 30.00%\\\\n",\\n-      "Correct:  3\\\\n",\\n-      "Wrong:    7\\\\n",\\n-      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\\\\n",\\n-      "Wall time: 5.25 ms\\\\n"\\n-     ]\\n-    }\\n-   ],\\n-   "source": [\\n-    "%%time\\\\n",\\n-    "perform_testing(recognizer)"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "markdown",\\n-   "metadata": {},\\n-   "source": [\\n-    "# 2. Local Binary Patterns"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 18,\\n-   "metadata": {\\n-    "collapsed": true\\n-   },\\n-   "outputs": [],\\n-   "source": [\\n-    "# face recognizer\\\\n",\\n-    "recognizer = cv2.face.createLBPHFaceRecognizer()"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 19,\\n-   "metadata": {\\n-    "collapsed": false\\n-   },\\n-   "outputs": [\\n-    {\\n-     "name": "stdout",\\n-     "output_type": "stream",\\n-     "text": [\\n-      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9]\\\\n",\\n-      "Trained 75 images\\\\n",\\n-      "\\\\n",\\n-      "CPU times: user 204 ms, sys: 0 ns, total: 204 ms\\\\n",\\n-      "Wall time: 198 ms\\\\n"\\n-     ]\\n-    }\\n-   ],\\n-   "source": [\\n-    "%%time\\\\n",\\n-    "perform_training(recognizer)"\\n-   ]\\n-  },\\n-  {\\n-   "cell_type": "code",\\n-   "execution_count": 20,\\n-   "metadata": {\\n-    "collapsed": false\\n-   },\\n-   "outputs": [\\n-    {\\n-     "name": "stdout",\\n-     "output_type": "stream",\\n-     "text": [\\n-      "Performing 10 tests\\\\n",\\n-      "\\\\n",\\n-      "Hosni_Mubarak is correctly recognized with confidence 70.3320301717\\\\n",\\n-      "Jeong_Se-hyun incorrect (recognized as Jesse_Jackson with confidence 66.9695790301)\\\\n",\\n-      "Aaron_Peirsol incorrect (recognized as Colin_Farrell with confidence 64.0263118099)\\\\n",\\n-      "Heizo_Takenaka is correctly recognized with confidence 62.2523363529\\\\n",\\n-      "Jesse_Jackson incorrect (recognized as Hugh_Grant with confidence 55.9830713166)\\\\n",\\n-      "Hugh_Grant is correctly recognized with confidence 58.4431455137\\\\n",\\n-      "Fernando_Gonzalez is correctly recognized with confidence 58.1942826626\\\\n",\\n-      "George_Clooney incorrect (recognized as Jeong_Se-hyun with confidence 61.8314192222)\\\\n",\\n-      "Colin_Farrell is correctly recognized with confidence 60.6598527609\\\\n",\\n-      "Charles_Taylor is correctly recognized with confidence 69.1481984626\\\\n",\\n-      "\\\\n",\\n-      "Accuracy: 60.00%\\\\n",\\n-      "Correct:  6\\\\n",\\n-      "Wrong:    4\\\\n",\\n-      "CPU times: user 88 ms, sys: 0 ns, total: 88 ms\\\\n",\\n-      "Wall time: 85.1 ms\\\\n"\\n-     ]\\n-    }\\n-   ],\\n-   "source": [\\n-    "%%time\\\\n",\\n-    "perform_testing(recognizer, testing_set)"\\n-   ]\\n-  }\\n- ],\\n- "metadata": {\\n-  "kernelspec": {\\n-   "display_name": "Tensorflow",\\n-   "language": "python",\\n-   "name": "tensorflow"\\n-  },\\n-  "language_info": {\\n-   "codemirror_mode": {\\n-    "name": "ipython",\\n-    "version": 3\\n-   },\\n-   "file_extension": ".py",\\n-   "mimetype": "text/x-python",\\n-   "name": "python",\\n-   "nbconvert_exporter": "python",\\n-   "pygments_lexer": "ipython3",\\n-   "version": "3.5.2"\\n-  }\\n- },\\n- "nbformat": 4,\\n- "nbformat_minor": 2\\n-}\\ndiff --git a/server/ai/predict.py b/server/ai/predict.py\\ndeleted file mode 100644\\nindex f839e0c..0000000\\n--- a/server/ai/predict.py\\n+++ /dev/null\\n@@ -1,25 +0,0 @@\\n-import cv2, cv2.face\\n-import os, os.path\\n-import sys\\n-import numpy as np\\n-import train\\n-from util import get_images_and_labels\\n-\\n-# Returns a boolean if an image matches with classifier, attach with confidence\\n-# -> is_match, confidence\\n-def match_classifier(classifer_file,\\n-                     image,\\n-                     algorithm=train.ALGO_LOCAL_BINARY_PATTERNS):\\n-\\n-    # create recognizer\\n-    FaceRecognizer = algorithm\\n-    recognizer = FaceRecognizer()\\n-\\n-    # load recognizer from classifier file\\n-    recognizer.load(classifer_file)\\n-\\n-    # perform prediction and confidence\\n-    label, confidence = recognizer.predict(image)\\n-    label = True if label == 1 else False\\n-\\n-    return label, confidence\\ndiff --git a/server/ai/train.py b/server/ai/train.py\\ndeleted file mode 100644\\nindex d7e401e..0000000\\n--- a/server/ai/train.py\\n+++ /dev/null\\n@@ -1,78 +0,0 @@\\n-import cv2, cv2.face\\n-import os, os.path\\n-import sys\\n-import numpy as np\\n-from util import get_images_and_labels\\n-\\n-# constants\\n-CASCADE_NAME = \\\'haarcascade_frontalface_default.xml\\\'\\n-ALGO_LOCAL_BINARY_PATTERNS = cv2.face.createLBPHFaceRecognizer\\n-ALGO_EIGEN = cv2.face.createEigenFaceRecognizer\\n-ALGO_FISHER = cv2.face.createFisherFaceRecognizer\\n-\\n-# perform training and generate classifiers\\n-def generate_classifiers(training_folder,\\n-                         classifier_folder,\\n-                         cascade_folder,\\n-                         algorithm=ALGO_LOCAL_BINARY_PATTERNS):\\n-\\n-    # Check if classifier folder exists\\n-    if not os.path.exists(classifier_folder):\\n-        print(\\\'Creating folder `%s`\\\' % classifier_folder)\\n-        os.makedirs(classifier_folder)\\n-\\n-    # Viola-Jones classifier for Haar feature extraction\\n-    cascader = None\\n-    if cascade_folder is not None:\\n-        cascade_path = os.path.join(cascade_folder, CASCADE_NAME)\\n-        cascader = cv2.CascadeClassifier(cascade_path)\\n-        assert(not cascader.empty())\\n-\\n-    # Setup cascader args\\n-    cascader_args = {\\n-        \\\'scaleFactor\\\': 1.1,\\n-        \\\'minNeighbors\\\': 2,\\n-        \\\'flags\\\': 2\\n-    }\\n-\\n-    # Get images and labels\\n-    images, labels = get_images_and_labels(training_folder,\\n-                                           cascader=cascader,\\n-                                           cascader_args=cascader_args,\\n-                                           debug_accuracy=True)\\n-\\n-    print(\\\'Collected %d images [%d labels]\\\' % (len(images), len(set(labels))))\\n-\\n-    FaceRecognizer = algorithm\\n-\\n-    label_dict = {label: 0 for label in labels}\\n-    index = 2\\n-    for label in label_dict:\\n-        label_dict[label] = index\\n-        index += 1\\n-\\n-    for label in label_dict:\\n-\\n-        recognizer = FaceRecognizer()\\n-\\n-        # create a binary recognizer per image\\n-        # current complexity: O(n^2)\\n-        # TODO: optimize this and integrate to TensorFlow\\n-        recognizer.train(images, np.array([1 if label == cur_label else 0 for image, cur_label in zip(images, labels)]))\\n-        # recognizer.train(images, np.array([\\n-            # 1 if label == cur_label else label_dict[label]\\n-            # for cur_label in labels]))\\n-\\n-        # Save classifier to text file\\n-        file_name = label + \\\'.xml\\\'\\n-        file_path = os.path.join(classifier_folder, file_name)\\n-\\n-        recognizer.save(file_path)\\n-        print(\\\'Saved classifier \\\' + os.path.abspath(file_path))\\n-\\n-if __name__ == \\\'__main__\\\':\\n-    args = sys.argv\\n-    if len(args) < 3:\\n-        print(\\\'Usage: python %s <training_folder> <classifier_folder> [<cascade_folder>]\\\' % args[0])\\n-    else:\\n-        generate_classifiers(args[1], args[2], \\\'../data/\\\' if len(args) == 3 else args[3])\\ndiff --git a/server/ai/util.py b/server/ai/util.py\\ndeleted file mode 100644\\nindex 1fdb592..0000000\\n--- a/server/ai/util.py\\n+++ /dev/null\\n@@ -1,84 +0,0 @@\\n-import cv2, cv2.face\\n-import os, os.path\\n-import sys\\n-import numpy as np\\n-def load_grayscale_image(image_file,\\n-                         equalize_hist=True,\\n-                         median_blur=3):\\n-\\n-    raw_image = cv2.imread(image_file)\\n-    gray_image = cv2.cvtColor(raw_image, cv2.COLOR_BGR2GRAY)\\n-    image = gray_image\\n-\\n-    if equalize_hist:\\n-        test = cv2.equalizeHist(image)\\n-\\n-    if median_blur:\\n-        image = cv2.medianBlur(image, median_blur)\\n-\\n-    return image\\n-\\n-# function that gets images with respective labels from a given folder\\n-def get_images_and_labels(folder,\\n-                          cascader=None,\\n-                          cascader_args={},\\n-                          debug=False,\\n-                          debug_faces=False,\\n-                          debug_accuracy=False,\\n-                          **kwargs):\\n-\\n-    labels = []\\n-    images = []\\n-    added = 0\\n-    expected = 0\\n-\\n-    for label in os.listdir(folder):\\n-\\n-        if debug: print(label)\\n-        path = os.path.join(folder, label)\\n-\\n-        if os.path.isdir(path):\\n-\\n-            for filename in os.listdir(path):\\n-\\n-                ok = 0\\n-                expected += 1\\n-\\n-                try:\\n-\\n-                    image_path = os.path.join(path, filename)\\n-                    image = load_grayscale_image(image_path, **kwargs)\\n-\\n-                    if cascader is not None:\\n-                        # get the face using Viola-Jones detector\\n-                        faces = cascader.detectMultiScale(image, **cascader_args)\\n-                        for (x, y, w, h) in faces:\\n-                            images.append(image[y:y+h, x:x+w])\\n-                            labels.append(label)\\n-                            if debug_faces:\\n-                                cv2.imshow(\\\'Adding faces to training set...\\\', image[y:y+h, x:x+w])\\n-                                cv2.waitKey(50)\\n-                        ok += len(faces)\\n-                        if len(faces) > 0:\\n-                            added += 1\\n-                    else:\\n-                        images.append(image)\\n-                        labels.append(label)\\n-                        ok = 1\\n-                        added += 1\\n-\\n-                except Exception as e:\\n-                    print(e)\\n-                    pass\\n-\\n-                if debug: print(\\\'\\\\t\\\' + filename + (\\\' [%d face]\\\' % ok))\\n-\\n-        if debug: print(\\\'[Added %d images]\\\' % added)\\n-\\n-    if debug_faces:\\n-        cv2.destroyAllWindows()\\n-\\n-    if debug_accuracy:\\n-        print(\\\'Accuracy: %.5f%%\\\' % (100 * added / max(1, expected)))\\n-\\n-    return images, labels\'\n\\ No newline at end of file\ndiff --git a/server/ai/facenet/align/align_dataset_mtcnn.py b/server/ai/facenet/align/align_dataset_mtcnn.py\nindex d2a3eea..009e7a9 100644\n--- a/server/ai/facenet/align/align_dataset_mtcnn.py\n+++ b/server/ai/facenet/align/align_dataset_mtcnn.py\n@@ -1,18 +1,18 @@\n """Performs face alignment and stores face thumbnails in the output directory."""\n # MIT License\n-# \n+#\n # Copyright (c) 2016 David Sandberg\n-# \n+#\n # Permission is hereby granted, free of charge, to any person obtaining a copy\n # of this software and associated documentation files (the "Software"), to deal\n # in the Software without restriction, including without limitation the rights\n # to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n # copies of the Software, and to permit persons to whom the Software is\n # furnished to do so, subject to the following conditions:\n-# \n+#\n # The above copyright notice and this permission notice shall be included in all\n # copies or substantial portions of the Software.\n-# \n+#\n # THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n # IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n # FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n@@ -45,15 +45,15 @@ def main(args):\n     src_path,_ = os.path.split(os.path.realpath(__file__))\n     facenet.store_revision_info(src_path, output_dir, \' \'.join(sys.argv))\n     dataset = facenet.get_dataset(args.input_dir)\n-    \n+\n     print(\'Creating networks and loading parameters\')\n-    \n+\n     with tf.Graph().as_default():\n         gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\n         sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n         with sess.as_default():\n             pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\n-    \n+\n     minsize = 20 # minimum size of face\n     threshold = [ 0.6, 0.7, 0.7 ]  # three steps\'s threshold\n     factor = 0.709 # scale factor\n@@ -61,7 +61,7 @@ def main(args):\n     # Add a random key to the filename to allow alignment using multiple processes\n     random_key = np.random.randint(0, high=99999)\n     bounding_boxes_filename = os.path.join(output_dir, \'bounding_boxes_%05d.txt\' % random_key)\n-    \n+\n     with open(bounding_boxes_filename, "w") as text_file:\n         nrof_images_total = 0\n         nrof_successfully_aligned = 0\n@@ -92,7 +92,7 @@ def main(args):\n                         if img.ndim == 2:\n                             img = facenet.to_rgb(img)\n                         img = img[:,:,0:3]\n-    \n+\n                         bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\n                         nrof_faces = bounding_boxes.shape[0]\n                         if nrof_faces>0:\n@@ -119,21 +119,21 @@ def main(args):\n                         else:\n                             print(\'Unable to align "%s"\' % image_path)\n                             text_file.write(\'%s\\n\' % (output_filename))\n-                            \n+\n     print(\'Total number of images: %d\' % nrof_images_total)\n     print(\'Number of successfully aligned images: %d\' % nrof_successfully_aligned)\n-            \n+\n \n def parse_arguments(argv):\n     parser = argparse.ArgumentParser()\n-    \n+\n     parser.add_argument(\'input_dir\', type=str, help=\'Directory with unaligned images.\')\n     parser.add_argument(\'output_dir\', type=str, help=\'Directory with aligned face thumbnails.\')\n     parser.add_argument(\'--image_size\', type=int,\n         help=\'Image size (height, width) in pixels.\', default=182)\n     parser.add_argument(\'--margin\', type=int,\n         help=\'Margin for the crop around the bounding box (height, width) in pixels.\', default=44)\n-    parser.add_argument(\'--random_order\', \n+    parser.add_argument(\'--random_order\',\n         help=\'Shuffles the order of images to enable alignment using multiple processes.\', action=\'store_true\')\n     parser.add_argument(\'--gpu_memory_fraction\', type=float,\n         help=\'Upper bound on the amount of GPU memory that will be used by the process.\', default=1.0)\ndiff --git a/server/ai/tensorflow_facenet_align_mtcnn.bat b/server/ai/tensorflow_facenet_align_mtcnn.bat\ndeleted file mode 100644\nindex 5df5851..0000000\n--- a/server/ai/tensorflow_facenet_align_mtcnn.bat\n+++ /dev/null\n@@ -1 +0,0 @@\n-python data/progvar_raw data/progvar_aligned --gpu_memory_fraction 0.6\ndiff --git a/server/ai/tensorflow_facenet_align_mtcnn.sh b/server/ai/tensorflow_facenet_align_mtcnn.sh\ndeleted file mode 100755\nindex 5215a21..0000000\n--- a/server/ai/tensorflow_facenet_align_mtcnn.sh\n+++ /dev/null\n@@ -1,6 +0,0 @@\n-#!/bin/sh\n-rm -rf data/progvar_aligned\n-python facenet/align/align_dataset_mtcnn.py \\\n-    data/progvar_raw \\\n-    data/progvar_aligned \\\n-    --gpu_memory_fraction 0.68'